{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-setup",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###############################################################\n",
    "cfile = cy.open_(runI[0], tag=tag, posix=posix, verbose=False)\n",
    "if cfile.x_resolution == 2048:\n",
    "    rescale = 512 # orca flash\n",
    "else:\n",
    "    rescale = 576 # fusion\n",
    "\n",
    "\n",
    "if not doRescale: \n",
    "    rescale = cfile.x_resolution\n",
    "    eps=5\n",
    "    min_samples = 40\n",
    "    \n",
    "    \n",
    "else:\n",
    "    eps=2\n",
    "    min_samples = 5\n",
    "\n",
    "        \n",
    "tscale = int(cfile.x_resolution/rescale)\n",
    "print(\"rascale: \", tscale)\n",
    "\n",
    "################################################################\n",
    "debug         = False\n",
    "columns = [\"iTr\", \"cluster_lable\", \"pixels\", \"photons\", \"ph_pixels\", \"x0start\", \"y0start\", \n",
    "          \"x0end\", \"y0end\", \"width\", \"height\", \"pearson\"]\n",
    "\n",
    "\n",
    "######################### Load PED #############################\n",
    "\n",
    "m_image, s_image = cy.ped_(run_ped, path=mybasepath+'ped/')\n",
    "\n",
    "#########################\n",
    "\n",
    "th_image   = np.round(m_image + nsigma*s_image)\n",
    "print (\"light over Th: %.2f \" % (th_image.sum()-m_image.sum()))\n",
    "\n",
    "start_time = time.time()\n",
    "# loop sui fle da analizaare\n",
    "for nRi in range(len(runI)):\n",
    "    try:\n",
    "        # open file\n",
    "        cfile = cy.open_(runI[nRi], tag=tag, posix=posix, verbose=True)\n",
    "    except:\n",
    "        print ('Problem in open file: ', runI[nRi])\n",
    "        break\n",
    "    #\n",
    "    # crea un db vuoto da riempire \n",
    "    df = pd.DataFrame(columns = columns)\n",
    "    # crea nome file di output\n",
    "    file_out = (mybasepath+\"out/dbscan_run%d_cmin_%d_cmax_%d_rescale_%d_nsigma_%.1f_ev_%d_ped_%d_%s.plk.gz\" % \n",
    "                (runI[nRi], cimin, cimax, rescale, nsigma, cfile.max_pic, run_ped, version))\n",
    "    #\n",
    "######## main loop sulle imagini da analizzare ###########\n",
    "    for iTr in range(0, cfile.max_pic): # cfile.max_image\n",
    "        #if iTr % 10 == 0: \n",
    "          # running & debug ...\n",
    "        print ('>>>> Processing RUN: ', runI[nRi], 'Event: ', iTr)\n",
    "          # end \n",
    "\n",
    "        image = rtnp.hist2array(cfile.file.Get(cfile.pic[iTr])).T\n",
    "        raw_image       = (image-m_image)\n",
    "        rebin_image     = cy.rebin(raw_image, (rescale, rescale))  \n",
    "        rebin_th_image  = cy.rebin((th_image-m_image), (rescale, rescale))\n",
    "        edges           = (rebin_image > rebin_th_image) & (rebin_image < cimax)         \n",
    "        points          = np.array(np.nonzero(edges)).T.astype(float) \n",
    "        \n",
    "        # X_scaled        = StandardScaler().fit_transform(cy.poit_3d(points, rebin_image)) # 3D\n",
    "        # dbscan          = DBSCAN(eps=0.045, min_samples = 20).fit(X_scaled) # eps=0.08 per 3D 0.04 2D\n",
    "        \n",
    "        dbscan          = DBSCAN(eps=eps, min_samples = min_samples).fit(points) \n",
    "        clusters        = dbscan.labels_\n",
    "        n_points      = len(clusters>-1)\n",
    "        if debug: print (\"Clustering Elapsed time: {:.1f}\".format(time.time() - start_time))\n",
    "        for ic in range (0, max(clusters)+1):\n",
    "            width = height = pearson = ph = dim = 0\n",
    "            yc = points[:,0][clusters==ic]\n",
    "            xc = points[:,1][clusters==ic]\n",
    "            \n",
    "            if fast:\n",
    "                            #\n",
    "            # attenzine NORMALIZZAZIONE per per rscale\n",
    "            #\n",
    "                ph, dim = cy.cluster_par(xc, yc, rebin_image) \n",
    "                width, height, pearson, _, _ = cy.confidence_ellipse_par(xc,yc)\n",
    "                ph     = ph*tscale*tscale\n",
    "                dim    = dim*tscale*tscale\n",
    "                width  = width*tscale\n",
    "                height = height*tscale            \n",
    "                if debug: print (\"Elapsed time fast: {:.1f}\".format(time.time() - start_time))\n",
    "            else:\n",
    "                zx1 = int(xc.mean() - 5*xc.std())\n",
    "                zx2 = int(xc.mean() + 5*xc.std())\n",
    "                zy1 = int(yc.mean() - 5*yc.std())\n",
    "                zy2 = int(yc.mean() + 5*yc.std())\n",
    "                \n",
    "                izoom = raw_image[zy1*tscale:zy2*tscale,zx1*tscale:zx2*tscale]            \n",
    "                width, height, pearson, ph, dim = cy.confidence_ellipse_par((xc-zx1)*tscale, (yc-zy1)*tscale, \n",
    "                                                                            image = izoom)\n",
    "                if debug: print (\"Elapsed time slow: {:.1f}\".format(time.time() - start_time))\n",
    "\n",
    "            for j in range(0, xc.shape[0]):\n",
    "                x=int(xc[j])\n",
    "                y=int(yc[j])\n",
    "                #ph += rebin_image[y,x]\n",
    "                if j == 0:\n",
    "                    x0start = x*tscale\n",
    "                    y0start = y*tscale\n",
    "            x0end = x*tscale\n",
    "            y0end = y*tscale\n",
    "\n",
    "            \n",
    "            # \n",
    "            # salva info per ogni cluster\n",
    "            #\n",
    "            df = df.append({columns[0]:iTr, columns[1]:ic, columns[2]:dim, columns[3]:ph, columns[4]:ph/dim, \n",
    "                            columns[5]:x0start, columns[6]:y0start, columns[7]:x0end, columns[8]:y0end, \n",
    "                            columns[9]:width, columns[10]:height, columns[11]:pearson},\n",
    "                            ignore_index=True)\n",
    "########### Debug  #####################################\n",
    "        if iTr % 10 == 0 or debug:\n",
    "            print (\"DEBUG: number of points, clusters: \" +str(n_points), ic) \n",
    "            print (\"Elapsed time 10 events: {:.1f}\".format(time.time() - start_time))\n",
    "            print ([str(columns[i])+': {:.2f}'.format(x) for i, x in enumerate (df.tail(1).values[0])])\n",
    "            fig, ax = plt.subplots (1,2, figsize=(10,5))\n",
    "            ax[0].imshow(rebin_image, vmin=-5, vmax=20)\n",
    "            yc = points[:,0][clusters>-1]\n",
    "            xc = points[:,1][clusters>-1]\n",
    "            ax[0].plot(xc,yc, 'r.', markersize=1, label=\"ic\"+str(ic))\n",
    "            ax[1].imshow(edges, cmap='YlGnBu', vmin=0,vmax=1)\n",
    "            plt.show()\n",
    "\n",
    "            if ic>0:\n",
    "                fig, ax = plt.subplots(1,5, figsize=(20,4))\n",
    "                yc = points[:,0][clusters==ic]\n",
    "                xc = points[:,1][clusters==ic]\n",
    "\n",
    "                zx1 = int(xc.mean() - 5*xc.std())\n",
    "                zx2 = int(xc.mean() + 5*xc.std())\n",
    "                zy1 = int(yc.mean() - 5*yc.std())\n",
    "                zy2 = int(yc.mean() + 5*yc.std())\n",
    "                izoom = raw_image[zy1*tscale:zy2*tscale,zx1*tscale:zx2*tscale] \n",
    "                ax[0].imshow(izoom, vmin=-5, vmax=30, aspect=\"auto\")\n",
    "                \n",
    "                py = np.sum(izoom, axis=0)\n",
    "                px = np.sum(izoom, axis=1)\n",
    "                \n",
    "                x = np.linspace(0, py.size, py.size)\n",
    "                ax[1].plot(x,py, \"navy\", label='Entries: {:d}\\nMeans {:.1f}\\nStd Dev {:.1f}'.format(x.size, \n",
    "                                                                                                    x.mean(), x.std()))\n",
    "                x = np.linspace(0, px.size, px.size)\n",
    "                ax[2].plot(x,px, \"navy\", label='Entries: {:d}\\nMeans {:.1f}\\nStd Dev {:.1f}'.format(x.size, \n",
    "                                                                                                    x.mean(), x.std()))\n",
    "\n",
    "                ax[3].imshow(rebin_image[zy1:zy2,zx1:zx2], vmin=-5, vmax=30, aspect=\"auto\")\n",
    "                el_plt, el_par = cy.confidence_ellipse(xc-zx1, yc-zy1, ax[3], edgecolor='yellow')\n",
    "                ax[3].scatter(xc-zx1, yc-zy1, color='red', label = ('(%.2f,%.2f)\\nP:%.2f\\nPh: %.2f\\nS: %d (%.1f)' %\n",
    "                                        (width, height, pearson, ph, dim, ph/dim)))\n",
    "                ax[4].imshow(edges[zy1:zy2,zx1:zx2], aspect=\"auto\")\n",
    "                ax[1].legend()\n",
    "                ax[2].legend()\n",
    "                ax[3].legend()\n",
    "                plt.show()\n",
    "            start_time = time.time()\n",
    "#################### close and save ################\n",
    "    df.to_pickle(file_out, compression='gzip')\n",
    "    print (\"out file\", file_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
